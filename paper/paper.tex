\documentclass{jsarticle}

\renewcommand{\labelenumii}{\theenumii}
\renewcommand{\theenumii}{\theenumi.\arabic{enumii}.}

\usepackage[dvipdfmx,hiresbb]{graphicx}
\usepackage{subcaption}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{comment}

\captionsetup[algorithm]{labelformat=empty}
\begin{document}

\tableofcontents



\section{序論}

\subsection{研究の背景}
グラフは情報科学に通底する問題ドメインであり、グラフを解き明かす探索アルゴリズムは分野の基本骨子をなしている。人工知能の分野においても探索は基盤となるアルゴリズムの一つであり、高速で効率的な探索アルゴリズムを研究することは人工知能於いては情報科学全体に意義のある研究である。さて、近年単一プロセッサの高速化は電力の限界を迎え、並列化による高速化へとパラダイムが移った。ハードウェアは今後も各CPUの計算速度の発展よりも並列化による高速化が進むだろうと予測されている。%要注釈 
故に今後ハードウェアの高速化の恩恵を引き出す為にはこの並列システムを利用したアルゴリズムを開発する必要がある。然るに探索アルゴリズムも単一プロセッサによる探索だけではなく、マルチコア・分散システムにおいてもそれぞれ効率的なアルゴリズムを研究しなければならない。


\subsection{関連研究}

グラフを探索するアルゴリズムのうち最も重要なものの一つとしてA*(エースター)アルゴリズムがある\cite{Hart1968}。このA*アルゴリズムを並列化する手法は数多く提案されている。

Kumarらはオープンリスト, クローズドリストをスレッド間で共有して並列に探索を行うParallel A*を提案し、性能評価を行った\cite{kumar1988parallel}。この手法はオープンリスト, クローズドリストのデータ構造を保つ為に相互排他ロックを必要とする。ノードが展開される度にオープンリストに、生成される度にクローズドリストにロックを獲得してアクセスする必要がある。その為Parallel A*は同期オーバーヘッドが非常に大きいという問題がある。\ref{sec:analysis2}で見るように、このシンプルな手法は逐次A*よりも遅くなってしまう。

同期オーバーヘッドを解決する手法としてKishimotoらはHash Distributed A*(HDA*)を提案した\cite{Kishimoto2013}。HDA*は各スレッドにローカルにオープンリストとクローズドリストを持つ。グラフのノードはHash関数によって均等かつ無作為に分割し各スレッドに割り当てられる。各スレッドは自分に割り当てられたノードのみを探索し、他スレッドに割り当てられたノードを生成した場合はそのスレッドにノードを非同期的に送信する。各スレッドのオープンリスト、クローズドリストは他のスレッドからアクセスされないので、相互排他ロックを必要としない。その為HDA*は同期オーバーヘッドが殆どない。HDA*は同期オーバーヘッドが殆どなく、スレッド間でノードの送信以外に大きな情報の通信を必要としないので、特に分散メモリ環境で有効な手法である。また、アルゴリズムの論理が非常にシンプルであるという利点もある。HDA*は逐次A*と比較してHash関数による分配が必要なだけであり、各スレッドの処理は逐次A*と殆ど同様である。並列アルゴリズムはデバッグが難しい為、シンプルであるということは非常に価値がある。HDA*の問題点としても、展開ノード数が大きくなることが指摘されている。HDA*において展開ノード数が増加する原因はまだ調べられていない。また、Kishimotoらの性能評価は殆ど分散メモリ環境におけるものであり、共有メモリ環境における実験は殆ど行われていない。また、それらも共有メモリ環境に最適化された実装を用いたものではない。その為、HDA*のマルチコアマシンにおける性能評価は不十分であると言える。

Burnsらは余剰な展開ノード数の小さい並列化アルゴリズムとして、Parallel Best-NBlock-First (PBNF)を提案した\cite{Burns2010}。PBNFは状態空間を複数のNBlockに分割する。それぞれのNBlockはオープンリストとクローズドリストを持つ。それぞれのスレッドは最も有望なノードを持つNBlockを占有し、探索を行う。自分の占有しているNBlockよりも有望なノードを持つNBlockが空いていれば、今探索していたNBlockを解放し、新しいNBlockを占有して探索を始める。あまりに頻繁なNBlockの切り替えが生じるのを防ぐために最小探索ノード数が設定される。これはチューニングの必要なパラメータである。NBlockはスレッドに占有されるので、オープンリスト・クローズドリストに相互排他ロックをかける必要がない。必要なロックは空いているNBlockを保存するheapのみである。その為PBNFは同期オーバーヘッドが小さい。PBNFは分散メモリ環境では有効ではないが、現在共有メモリ環境で最もパフォーマンスの良いstate-of-the-artの手法であるとされている。PBNFの問題点として、その複雑さが挙げられる。すなわち、PBNFのパフォーマンスを引き出す為には空間をNBlockに分割する方法・粒度と最小探索ノード数をドメインに対して最適化をする必要がある。

また、BurnsらはマルチコアマシンでHDA*を含めた様々な並列アルゴリズムの性能比較を行い、その中でPBNFとHDA*を有望な(高速な)アルゴリズムとした。また、その上でPBNFはHDA*より速いと結論をした。その理由としては、PBNFはHDA*よりも探索ノード数が小さいという結果があったことを指摘した。しかしながら、Burnsらの比較実験には複数問題点がある。KishimotoらのHDA*の実装がZobrist Hash\cite{Zobrist1970}を用いていたのに対してBurnsらはNaiveなHash関数を用いている。Hash関数によってHDA*の性能は大きく異なると考えられるが、その違いは検証されていない。また、オープンリストをheapで実装しているが、これはBurnsらがベンチマーク問題として扱っている15 Puzzle、4 way Grid-pathfindingにおいて最適な実装ではない\cite{burns2012implementing}。もう一つ重要な問題点として、ベンチマーク問題のサイズが小さいということが挙げられる。並列アルゴリズムは初期化に時間がかかる為、ある程度問題サイズが大きいものでないと実質的な高速化効率を正確に測ることが出来ない。Burnsらの用いた問題集はA*探索で10秒未満のものが多く、それらが十分な大きさであるかは検証の必要がある。

これらの理由から、HDA*とPBNFはより詳細な性能評価が必要であると考えられる。また、HDA*のHash関数による挙動の違いも重要な問題である。また、両アルゴリズムのオープンリストの実装がそれぞれどのような影響を与えるかも調査する必要がある。

\subsection{研究の目的}

本研究の目的は２つある。

\begin{enumerate}
\item HDA*の探索ノード数の増加の原因を分析する。
\newline

HDA*におけるノードの探索順をA*と比較をすることで探索ノード数の増加の原因を分析する。また、Zobrist Hashだけではなく、Burnsらの実装したNaiveなHash関数を使った場合の比較も行う。HDA*のノードの展開速度を遅くした場合の比較も行う。
\newline

\item マルチコア環境において、HDA*とPBNFの性能評価を行う。
\newline

まず、HDA*のhash関数を変えた際の挙動を調べる。次にHDA*とPBNFのオープンリストの実装をvectorとheapにした場合の性能の違いを調べる。それらの結果を踏まえ、最適なHDA*とPBNFの実装をもって性能の比較を行う。

\end{enumerate}


\subsection{本論文の構成}

本論文は以下の通りに構成される。
2章でA*探索の詳細とA*探索の並列化手法について述べる。3章は本研究で扱うベンチマーク問題の問題ドメインについて解説する。4章はHDA*の探索ノード数の増加を解析する。5章ではHDA*とPBNFのチューンアップを行ったのち、性能の比較評価を行う。6章は本研究で行った実験・解析から得られる知見をまとめる。

\section{A*探索とその並列化}
\label{sec:define}

\subsection{A*探索}

A*探索アルゴリズム(A*, A*探索)はヒューリスティック関数によって、展開された探索空間の中で最も有望であるノードを推定し、そのノードを優先して探索するアルゴリズムである\cite{Hart1968}。ヒューリスティック関数を利用しないブラインド探索と比較して高速に最適解を見つけられることが多い。A*探索は以下のようなアルゴリズムである。

\begin{enumerate}
	\item 初期状態をオープンリストに加える。
	\item オープンリストにあるノードの中でゴール状態までの見積りが最小であるノードを展開する。
	\begin{enumerate}
		\item 展開したノードをオープンリストから取り除き、クローズドリストにその状態を加える。
		\item 展開した状態がゴール状態かどうかを調べる。ゴール状態である場合は解を出力して終了する。
		\item 目標状態でない場合、展開した状態から１つの行為で遷移可能な状態のうち、クローズドリストにないすべての状態をオープンリストに加える。
	\end{enumerate}
	\item オープンリストが空になった場合は解なしとして終了する。
\end{enumerate}

オープンリストは未探索のノード、クローズドリストは探索済のノードが保存されるデータ構造である。あるノード$n$からゴール状態までの見積り$f(n)$は$f(n) = g(n) + h(n)$で計算される。$g(n)$は初期状態からノード$n$までの経路にかかったコストである。$h(n)$は状態からゴール状態までの距離を推定するヒューリスティック関数である。ヒューリスティック関数がadmissibleであるならば、A*探索の解の最適性が保証される。ヒューリスティック関数がadmissibleであるとは、ゴール状態までの推定コストを過小に見積もることがないということである。以降の議論では、並列化したアルゴリズムと区別する為に逐次A*と呼ぶ。


\subsection{A*探索の並列化にかかるオーバーヘッド}

並列探索は、理想的にはスレッドの数だけ高速化する。しかしながら、一般に並列探索は並列に伴うオーバーヘッドが生じる。並列化のオーバーヘッドは以下の３つに分類される。

\begin{enumerate}
\item 探索オーバーヘッド
\newline

一般に並列探索は逐次A*よりも多くのノードの展開を必要とする。並列化に伴い余剰に探索したノードの割合を探索オーバーヘッドと呼ぶ。本研究では、探索オーバーヘッドは以下の式によって推定する。

$SO := \frac{並列実行によって展開したノード数}{逐次実行によって展開したノード数}$ %
\newline

$SO$は理想的には1になるが、多くの場合1よりも大きくなる。
\newline

\item 同期オーバーヘッド
\newline

同期オーバーヘッドは、他スレッドの処理を待つ為にアイドル状態で待たなければならない場合に生じる。データ構造の一部は同時に複数のスレッドがアクセスすることが出来ない。そのようなデータ構造をスレッド間で共有する場合は相互排他ロックを必要とする。相互排他ロックは、ロックを獲得したスレッド以外のスレッドによるアクセスを禁止する制御機構である。あるスレッドが他スレッドによって獲得された相互排他ロックが解放されるまで待つ場合、同期オーバーヘッドとなる。
\newline

\item 通信オーバーヘッド
\newline

通信オーバーヘッドはスレッド間の通信にかかる遅延である。スレッド間の通信は仕事の分配や情報の共有の為に行われる。

\end{enumerate}

これらのオーバーヘッドはトレードオフの関係にある。理論的にこれらを最小にすることは非常に困難である為、多くの場合は実験的に最適な実装にチューニングが行われる。

並列化にかかるオーバーヘッドの計測の為には高速化効率(efficiency)という指標が用いられる。Efficiencyは以下のように定義される。
\newline

$Efficiency := \frac{逐次実行による実行時間}{並列実行による実行時間 \times スレッドの数}$ % TODO: の字体を修正
\newline

Efficiencyは理想的には1になるが、上述のオーバーヘッドがかかる為に多くの場合1未満である。Efficiencyが1の場合をPerfect linear speedupと呼ぶ。Efficiencyが1を越える場合をSuperlinear speedupと呼ぶ。

本研究では探索オーバーヘッドと高速化効率を主な指標として用いる。

\subsection{Parallel A*}

最もシンプルなA*の並列化手法はKumarらの提案したParallel A*である\cite{kumar1988parallel}。Parallel A*は各スレッドでA*探索を行う。スレッド間でオープンリスト, クローズドリストを共有することで並列に探索をすることが出来る。この手法はオープンリスト, クローズドリストのデータ構造を保つ為に相互排他ロックを必要とする。各スレッドはノードを展開する度にオープンリストに、ノードを生成する度にクローズドリストにロックを獲得してアクセスする必要がある。その為Parallel A*は同期オーバーヘッドが非常に大きいという問題がある。\ref{sec:analysis2}章で見るように、このシンプルな手法は逐次A*よりも遅くなってしまう。

\subsection{HDA*}

HDA*は各スレッドにローカルにオープンリストとクローズドリストを持つ。グラフのノードはHash関数によって均等かつ無作為に分割し各スレッドに割り当てられる。各スレッドは自分に割り当てられたノードのみを探索し、他スレッドに割り当てられたノードを生成した場合はそのスレッドにノードを非同期的に送信する。HDA*はまず、ルートプロセスで初期状態を展開する。その後、それぞれのスレッド$P$は最適解を発見するまで以下のループを繰り返す。


\begin{enumerate}
\item $P$は自分のメッセージキューに新しいノードが入っているかを確認する。もし入っていたら、それぞれのノードを$P$のクローズドリストと照合し、オープンリストに入れるべきかを確認する。

\item メッセージキューが空なら、$P$のオープンリストから最も優先度の高いノードを展開し、新しいノードを生成する。生成されたノード$s$に対してそれぞれハッシュキー$K(s)$を計算する。ノード$s$は$K(s)$を担当するプロセッサのメッセージキューに送信される。この送信は非同期的で、ロックを必要としない。$P$は送信先からの返信を待たずに次の計算に移る。

\end{enumerate}

HDA*のHash関数はHDA*の性能に非常に重要である。Hash関数に求められる要件は以下である。

\begin{enumerate}
\item 全てのスレッドに対してなるべく均等される。
\item 状態空間に対してなるべく不偏かつ均等な分配である。
\item Hash値を高速に求めることが出来る。
\end{enumerate}

以上の要件から、多くのドメインにおいてZobrist Hash\cite{Zobrist1970}が使われる。ノード$s$の状態が整数列$\mathbf{x}$で表現されるとする。状態の$i$番目の整数の取りうる値は$l_{i}$通りあるとする。ノードの状態を$\mathbf{x} = (x_{0}, x_{1}, …, x_{n})$と置く。この時$x_{i}$は$0 \leq x_{i} \l l_{i}$である。$R_{i}$を$l_{i}$個の値を持つテーブルとする。$R_{i}$は予めランダムに生成される。ここでZobrist Function $Z(s)$は以下のように定義される。
\newline

$Z(s) := R_{0}[x_{0}]$ $xor$ $R_{1}[x_{1}]$ $xor$ $…$ $xor$ $R_{n}[x_{n}]$ %
\newline

$R_{i}$はランダムに生成される為、$Z(s)$は均等な確率で定義域の全ての値が出ると期待される。また、状態の全情報を利用して生成される為、局所的な状態の変化に対しても不偏な分配を行うことが出来る。$xor$によって計算する為、親ノードからの差分のみを計算してHash値を求めることが出来る。加えて、XOR命令は非常に速い計算である。よってZobrist Hashは高速に求めることが出来る。


\subsection{PBNF}

Parallel Best-NBlock-First (PBNF)PBNFは状態空間を複数のNBlockに分割し、各スレッドがNBlockを交換しながら探索する手法である\cite{Burns2010}。それぞれのNBlockはオープンリストとクローズドリストを持つ。それぞれのスレッドは最も有望なノードを持つNBlockを占有し、探索を行う。また、占有したNBlockに隣接するNBlockをスレッドのinterference scopeに加える。他のスレッドのinterference scopeに加わったNBlockを探索することは出来ない。同一のNBlockは複数のinterference scopeに入ることが出来る。自分の占有しているNBlockよりも有望なノードを持つNBlockが空いていれば、今探索していたNBlockとinterference scopeを解放し、新しいNBlockを占有して探索を始める。あまりに頻繁なNBlockの切り替えが生じるのを防ぐために最小探索ノード数が設定される。これはチューニングの必要なパラメータである。NBlockはスレッドに占有されるので、オープンリスト・クローズドリストに相互排他ロックをかける必要がない。必要なロックは空いているNBlockを保存するheapのみである。

PBNFはLivelockが起こる可能性がある。Livelockは、複数のスレッドが同じ資源を解放する処理を実行しているにも拘らず、どちらのスレッドも資源が獲得出来ない状況である。あるNBlockが複数のスレッドのinterference scopeに入っている場合、どのスレッドもそのNBlockを探索することが出来ない状態になりうる。Burnsらはこの問題を解決したSafePBNFを提案し、SafePBNFにおいてLivelockが発生しないことを証明した。SafePBNFは、あるNBlockが複数のスレッドのinterference scopeに入っている場合、このNBlockをhotとする。hotなNBlockを探索する要求があった場合、そのNBlockをinterference scopeに含むスレッドは現在探索しているNBlockを解放する。これによって、Livelockを防ぐことが出来る。

Livelockの可能性のあるアルゴリズムは完全ではない。アルゴリズムが完全であるとは、健全性と停止性を満たすことである。健全性とはアルゴリズムの結果が正しいことであり、停止性とはどのような入力に対しても有限時間内に結果を出力して停止することである。PBNFはLivelockが生じる可能性があるので、停止性を満たさない。本研究で扱うA*, Parallel A*, HDA*は全て完全なアルゴリズムである。よって、同じ完全なアルゴリズムであるSafePBNFを比較の対象とする。

\begin{algorithm}                      
\caption{PBNF search framework}         
\label{alg:pbnf}                          
\begin{algorithmic}                  
\WHILE {there is an nblock with open nodes}
	\STATE lock; $b \leftarrow$ best free nblock; unlock
	\WHILE {$b$ is no worse than the best free nblock or we've done fewer than $m$ expansions}
		\STATE $n \leftarrow$ best open node in $b$
		\IF {$f(n) \leq f(incumbent)$}
			\STATE prune all open nodes in $b$
		\ELSIF { $n$ is a goal }
			\STATE $incumbent \leftarrow n$
		\ELSE 
			\STATE for each child $c$ of $n$
			\STATE insert $c$ in the open list of the appropriate nblock
		\ENDIF
\ENDWHILE
\ENDWHILE
\end{algorithmic}
\end{algorithm}



\section{問題ドメイン}

\subsection{Sliding-tile Puzzle (15 Puzzle, 24 Puzzle)}

\begin{figure}
	\centering
	\includegraphics[width=0.3\columnwidth]{others/15puzzle.png}
	\caption{Sliding-tile Puzzle}
	\label{fig:15puzzle}
\end{figure}% 

四角い枠にタイルが敷き詰められている。枠には一ヶ所タイルのない場所があり、そこに縦と横からタイルをスライドすることが出来る。Sliding-tile Puzzleは、タイルのスライドによって初期状態から特定のゴール状態まで動かす経路を求める問題である。15 Puzzleの状態空間の大きさはおよそ$10^{13}$状態、24 Puzzleの状態空間はおよそ$10^{25}$状態である。

本研究では15 Puzzleのヒューリスティック関数はマンハッタン距離を用いた。マンハッタン距離ヒューリスティックは、各タイルのゴール状態での位置までのマンハッタン距離の総和で求められる。タイルは同時に２つ動かすことは出来ない。また、あるタイルがゴール位置に動かす為には少なくともマンハッタン距離の回数だけ動かす必要がある。よって、マンハッタン距離ヒューリスティックはadmissibleなヒューリスティック関数である。

15 Puzzleはノードの展開が非常に高速なドメインである。ノードの展開が速いドメインは並列化によって高速化することが困難である。なぜならば、展開が高速である分、同期オーバーヘッドや通信オーバーヘッドによる遅延の影響が大きくなるからである。15 Puzzleドメインにおいて高速化が可能であれば、多くのドメインにおいても同様に高速化が可能であると考えられる。この理由から、15 Puzzleは並列探索のベンチマーク問題として広く使われている。本研究でも主に15 Puzzleをベンチマーク問題として使った。

24 Puzzleのヒューリスティック関数はDisjoint pattern database heuristicsを用いた\cite{Korf2002}。Disjoint pattern database heuristicsはCulbersonらの提案したPattern databasesを拡張したヒューリスティックである。Pattern database heuristicsは問題の部分問題に対する最適解のコストを予めデータベースに記録し、ヒューリスティック関数として用いる手法である\cite{culberson1998pattern}。Disjoint pattern databasesは複数のPattern databaseを用いることで複数の部分問題のコストの和をヒューリスティック関数とする。Sliding-tile Puzzleにおいては、タイルを複数のグループに分ける。同じタイルは２つ以上のグループに含まれない。それぞれのグループにおいて、そのグループ内のタイルがゴール位置にたどり着く為の最小コストを求め、データベースに保存する。ある状態に対して、それぞれのグループがゴール位置にたどり着く為の最小コストをデータベースから読み、それらの和をヒューリスティックの値とする。この値は少なくともマンハッタン距離以上である。マンハッタン距離がタイル間の相互作用を考慮しないのに対して、このヒューリスティックは同じグループ間の相互作用を考慮するので、多くの場合はマンハッタン距離よりも大きい。


\subsection{Grid Pathfinding}

Grid Pathfindingは二次元のグリッドにおいて、障害物を避けつつ初期位置からゴール位置までの経路を求める問題である。本研究では4 way Grid Pathfindingを扱った。4 way Grid Pathfindingでは上下左右の位置にあるグリッドに移動することが出来る。本研究ではグリッドの大きさを5000$\times$5000、障害物のある確率を0.45に設定した。本研究ではゴール距離までのマンハッタン距離をヒューリスティック関数とした。マンハッタン距離はadmissibleなヒューリスティック関数である。

\subsection{Travelling Salesperson Problem (TSP)}

Travelling Salesperson Problem (TSP)は、都市の集合とそれぞれの２都市間の距離が与えられたとき、全ての都市を一度ずつ訪れ、出発都市に戻る為の最短経路を求める問題である。TSPで使われるヒューリスティック関数の一つはMinimum Spanning Treeである。Minimum Spanning Treeはグラフの全ての頂点を含む、最も辺の長さが小さい部分グラフである。これはゴールまでの経路よりも短いか同等である。なぜなら、ゴールまでの経路の方が短いならば、それがMinimum Spanning Treeになるはずであるからである。よって、Minimum Spanning Treeはadmissibleなヒューリスティック関数である。

\section{並列化に伴う探索オーバーヘッドの定性的な解析}
\label{sec:analysis1}

\subsection{先行研究における探索オーバーヘッドの解析}

探索オーバーヘッドは逐次A*と比較した展開ノードの増加率である。ここで、探索オーバーヘッドは以下のように定義する。

$SO := \frac{並列実行によって展開したノード数}{逐次実行によって展開したノード数}$

Kishimotoらはf値によって探索ノードの分類を行うことでHDA*の探索オーバーヘッドの分析を行った\cite{Kishimoto2013}。c*を最適解のコストとする。探索したノードのうち、f値が$f < c*$となるノードの割合を$R_{<}$, $f = c*$となるノードの割合を$R_{=}$, $f > c*$となるノードの割合を$R_{>}$, 重複して展開されたノードの割合を$R_{r}$とおく。逐次A*で探索されるノードのf値は$f < c*$または$f = c*$である。$f > c*$となるノードは展開されない。同じ状態のノードが複数回展開されることもない。対してHDA*を含む並列アルゴリズムは同じノードを複数回展開しうる。また、$f > c*$のノードも展開しうる。$f = c*$の展開ノード数もA*と異なる。よって、$R_{=}$, $R_{>}$, $R_{r}$の割合によって探索オーバーヘッドを分類することが出来る。
しかしながらこれらの探索オーバーヘッドの原因に対する分析はまだ行われていない。すなわち、$R_{=}$, $R_{>}$, $R_{r}$となるノードがなぜ生じるのかは分析されていない。

\subsection{HDA*のノードの探索順}

探索オーバーヘッドは、A*と探索順が異なることが原因であると考えることが出来る。ノードの展開する順番がA*と完全に一致するならば、探索オーバーヘッドは全く生じない。裏を返せば、A*と探索順の異なる場合に探索オーバーヘッドが生じると考えられる。よって、HDA*の状態の探索順をA*のそれと比較をすることで、どのようなパターンで探索オーバーヘッドが生じるのかを分析することが出来ると考えられる。
本実験では15 Puzzleドメインを対象にA*とHDA*においてある状態が探索された順番を記録した。インスタンスはランダムに生成した100問を対象とした。実験環境はIntel dual-quad Xeon 2.33GHz, 32GB mem, OSはGNU/Linux Ubuntu 14.04である。本実験では15 Puzzleドメインに最適化したドメイン依存のコードを実装した。KishimotoらはMPI message passing libraryでプロセス間通信を実装したが、本実験では共有メモリ環境においてMPIよりも高速なpthreadライブラリを用いた。オープンリストはvectorで実装した。なお、オープンリストをheapで実装した場合も同様の結果が得られた。


\begin{figure}
	\begin{subfigure}{0.6\columnwidth}
		\centering
		\includegraphics[width=\columnwidth]{order/2_threads.png}
		\caption{HDA* 2 threads}
		\label{fig:order_2_threads}
	\end{subfigure}
	\begin{subfigure}{0.6\columnwidth}
		\centering
		\includegraphics[width=\columnwidth]{order/4_threads.png}
		\caption{HDA* 4 threads}
		\label{fig:order_4_threads}
	\end{subfigure}
	\begin{subfigure}{0.6\columnwidth}
		\centering
		\includegraphics[width=\columnwidth]{order/8_threads.png}
		\caption{HDA* 8 threads}
		\label{fig:order_8_t8hreads}
	\end{subfigure}
	\begin{subfigure}{0.6\columnwidth}
		\centering
		\includegraphics[width=\columnwidth]{order/delay.png}
		\caption{delayed expanding HDA*}
		\label{fig:order_delay}
	\end{subfigure}
	\caption{HDA*の探索順}
	\label{fig:hdastar_orders}
\end{figure}% TODO: PNGファイルの扱い


\ref{fig:order_2_threads}は、ある状態がA*において何番目に展開されたかを横軸に、HDA*において何番目に展開されたかを縦軸に取ってある。これらの結果はそれぞれ1インスタンスのものを代表的に示したが、実験対象とした100問のどのインスタンスに対しても同様のパターンを確認することが出来た。

HDA*のノードの探索順は大きな流れとしてはA*のそれと一致するようである。しかしながら「幅」が存在し、その範囲内で展開順が前後する。また、この幅はスレッド数が大きくなると広がる。この幅は実行時間を通して大きくなっていくが、展開ノード数が増加する割合に対して小さい。その為、問題サイズが大きいほど、展開ノード数に対する相対的な幅の大きさは小さくなる。

また、探索の冒頭に展開順が大きくA*から外れる部分がある。これは初期化の終わっていないスレッドがある時間帯に当たる。初期化の終わっていないスレッドがある場合限られた探索空間の中で展開を進めることになる。探索空間が異なるので、展開順もA*から外れてしまうと考えられる。また、ここで探索されたノードは殆どが重複したノードになる。限られた探索空間内を迂回して展開したノードであるので、殆どのノードは最短ではない経路で生成される為である。\ref{fig:order_delay}はノードの展開に無関係の計算を挿入し、展開速度をた場合の実行結果である。\ref{fig:order_delay}の実行の展開速度は39854.8ノード/秒である。ノードの展開が遅い場合にはこの現象は起こらないという結果を得た。

HDA*においては、ある状態に対して複数の経路があり、より長い経路が先に探索された場合にノードの重複が生じる。しかし15 Puzzleドメインではほとんど重複は生じなかった。生じた重複はほぼBurst Effectで生じたものである。15 Puzzleの探索空間はグラフというより木構造に近く、探索中に同じ状態を生成することは少ない。その為、15 Puzzleでは重複は殆ど発生しなかったのだと考えられる。Kobayashiらがノードの重複が問題となるシーケンスアライメント問題において、ノードの重複による探索オーバーヘッドついて議論しているのでこちらを参照されたい\ref{Kobayashi2011evaluations}。


\subsection{探索オーバーヘッドの分類}

前節の結果から、Zobrist Hashを用いたHDA*の探索オーバーヘッドの原因を３つに分類した。

\begin{enumerate}
\item Bind Effect
\newline
HDA*とA*の展開順が幅の中で前後する為に生じる探索オーバーヘッド。A*と展開順が前後するので、実行時間の最後に、逐次A*であれば展開しないノードを展開してしまう。ここで余剰に展開するノードの数は幅の大きさに従う。幅の大きさは問題サイズが大きいほど相対的に小さくなるので、Bind Effectによる探索オーバーヘッドは問題サイズが大きくなるほど小さくなる。なお、Bind EffectによってA*よりも速くゴール状態を展開することもある。$f < c*$のノードが全て展開されていれば、その時点で探索を終了することが出来る。この場合super linear speedupが生じうる。
\newline

\item Burst Effect
\newline
スレッドの初期化にかかる時間の為に生じる探索オーバーヘッド。Burst Effectは探索の冒頭にしか生じない為、問題サイズが大きいほど、Burst Effectによる探索オーバーヘッドの割合は小さくなる。この現象はノードの展開速度が速い場合に起こると考えられる。
\newline

\item Duplicate
\newline
ノードの重複による探索オーバーヘッド。ある状態に対して複数の経路があり、より長い経路が先に探索された場合に重複が生じる。本研究で扱うドメイン(15 Puzzle, 24 Puzzle, Grid Pathfinding, Travelling Salesperson Problem)では殆ど発生しない為、分析の対象外とする。

\end{enumerate}

\begin{figure}
	\centering
	\includegraphics[width=0.6\columnwidth]{order/naive_hash.png}
	\caption{naive hash HDA*}
	\label{fig:order_naive_hash}
\end{figure}

上述の探索オーバーヘッドの分類は十分な性能のHashを必要とすると考えられる。\ref{fig:order:naive_hash}はBurnsらHDA*の性能評価に用いたNaive HashによるHDA*の探索順である。Naive Hashは状態$s$に対して以下の式で与えられる。

$H(s) = \sum\nolimits_{i = 0}^{15}(16^{i} \times tiles_{i})$ $mod$ $n$

ただし$n$はスレッドの数、$tiles$は各タイル$i$の位置である。Naive Hash分配はうまくいっていないようである。$n = 2, 4, 8$の場合、Hash値は$tiles_{i}$の値のみに依存する。このとき、Naive Hashは15 Puzzleドメインの状態空間を均等に分割する。しかしながら、Naive Hashは状態の一部分の情報しか利用していない為、状態空間に対して不偏的に均等な分割をすることが出来ない。探索で現れる状態は15 Puzzleドメインの状態空間に対して非常に小さく、偏りのある部分集合であるので、均等な分配にならないと考えられる。Zobrist HashとNaive Hashの詳細な性能比較は次章で行う。

\begin{figure}
	\centering
	\includegraphics[width=0.6\columnwidth]{order/safepbnf.png}
	\caption{SafePBNF}
	\label{fig:order_safepbnf}
\end{figure}


また、\ref{fig:order_safepbnf}はPBNFの探索順である。A*の探索順とは大きく異なる順番でノードを探索していることが伺える。
%実はweighted searchに近い効果があるのでは？
\newline

Bind Effect, Burst Effectは問題サイズが大きくなるに従い相対的に小さくなる。Duplicateは本ドメインにおいては問題となる大きさではない。以上の分析から、Zobrist Hashを用いたHDA*の探索オーバーヘッドは問題サイズが大きくなる程小さくなると推測される。次節にてこれを実験的に検証する。

\subsection{問題サイズに対するHDA*の探索オーバーヘッドとパフォーマンスの変化}
\label{sec:speedup_size}

前項の分析にて、問題サイズが大きくなるほど探索オーバーヘッドが小さくなるという仮説を議論した。本節ではこの仮説を実験的に検証する。15 Puzzle, 24 Puzzleドメインを対象に、問題毎の探索ノード数と高速化効率の分析を行った。15 Puzzleのインスタンスはランダムに生成した200問を対象にした。これらの問題はA*探索で10～3000秒の実行時間で解ける問題である。24 PuzzleはKorfによる50問のうち、25, 32, 34, 38, 40番の問題を対象とした\cite{Korf2002}。

\begin{figure}
	\centering
	\includegraphics[width=0.4\columnwidth]{eps/search_overhead.pdf}	
	\caption{Search Overhead (15 Puzzle)}
	\label{fig:david_so}
\end{figure}
\begin{figure}
	\centering
	\includegraphics[width=0.4\columnwidth]{eps/efficiency.pdf}	
	\caption{Efficiency (15 Puzzle)}
	\label{fig:david_speedup}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=0.4\columnwidth]{eps/search_overhead_24puzzle.pdf}	
	\caption{Search Overhead (24 Puzzle)}
	\label{fig:david_so_24}
\end{figure}
\begin{figure}
	\centering
	\includegraphics[width=0.4\columnwidth]{eps/efficiency_24puzzle.pdf}	
	\caption{Efficiency (24 Puzzle)}
	\label{fig:david_speedup_24}
\end{figure}

\ref{fig:david_so}の図は横軸に逐次A*探索における実行時間、縦軸に探索オーバーヘッドを取っている。この図を見ると、問題サイズが大きくなるほど、探索オーバーヘッドが1に近づいているのが分かる。同様の傾向が\ref{fig:david_so_24}でも見られる。

\ref{fig:david_speedup}の図は横軸に逐次A*探索における実行時間、縦軸に高速化効率を取っている。全体の傾向として問題サイズが大きくなる程に高速化効率が大きくなり、1000秒程度でperfect linear speedupに近づくことが確認出来る。HDA*は、逐次A*で1000秒程度の問題サイズであればほぼperfect linear speedupが得られるようである。
%それぞれの実行は一回の実行結果を比較しているので偶然的な要素を含む。例えば、bind effectによって偶然A*よりも速い順番で最適解を発見したインスタンスも多い。
興味深い現象として、特に大きな問題インスタンスに対してしばしばsuperlinear speedupが生じる。多くのインスタンスにおいて発生している為、偶然的な要素だけでは説明されないと考えられる。逐次A*と1スレッドのHDA*の実行時間はほぼ同じであるので、本実験のA*の実装に問題があるとは考えにくい。また、Kishimotoらの分散メモリ環境における24 Puzzleの実験においても、一部のインスタンスでsuperlinear speedupが生じている\ref{Kishimoto2013}。高速化効率の大きいインスタンスは、スレッドの数が変化しても大きい場合が多いようである。高速化効率の大きさはインスタンスに強く依存しているのではないかと推察される。高速化効率がインスタンスのどのような特徴に依存しているかは今後の研究課題である。

アルゴリズムの性能評価は平均の実行時間や探索ノード数を論じることが殆どである。これは上述の偶然的な要素を取り除く為である。しかしながら、並列探索における高速化効率は問題サイズに対して依存する。然るに本質的な高速化効率への知見を得るためには、平均化した高速化効率による議論ではなく、問題サイズ毎に検討をする必要がある。その為、次章の議論において高速化効率や探索オーバーヘッドは平均値ではなく、問題インスタンス毎に示す。


\section{HDA*とPBNFの性能比較実験}
\label{sec:analysis2}

\subsection{先行研究における比較実験の問題点}

Burnsらの比較実験には複数問題点がある\cite{Burns2010}。まず、HDA*のHash関数を汎用なHash関数によって実装しているが、KishimotoらはZobrist Hashを用いて実装した。Hash関数によってアルゴリズムの挙動は異なると考えられるが、その違いは検証されていない。また、Burnsらの実験ではHDA*, PBNFのオープンリストをheapで実装している。多くのドメインはオープンリストをvectorで実装することが出来る。heapに対するアクセスが$O(logn)$であるのに対してvectorへのアクセスは$O(1)$である。Burnsらは別の論文で、15 Puzzleドメインを対象にA*探索の最適化を議論しており、heapとvectorの比較実験を行いvector実装が3倍程度高速であると結論した\cite{burns2012implementing}。HDA*とPBNFは複数のオープンリストがある。HDA*はスレッドの数に分割され、PBNFはNBlockの数に分割される。NBlockは15 Puzzleの場合3360個に分割される。両アルゴリズムは各オープンリストが小さくなるので、高速化の割合はそれぞれ逐次A*における３倍よりも小さくなると推測されるが、まだ検証はされていない。もう一つ重要な問題点として、ベンチマーク問題のサイズが小さいということが挙げられる。\ref{sec:speedup_size}で議論したように、HDA*の高速化効率は1000秒程度の問題まで向上し続け、ほぼperfect linear speedupになる。しかしながらBurnsらの用いた問題集はA*探索で10秒未満のものが殆どである。よって、ベンチマーク問題の問題サイズを考慮した比較・解析が必要である。
\newline
以下の実験の実験環境は\ref{sec:analysis1}章と同様である。マシンはIntel dual-quad Xeon 2.33GHzプロセッサ, 32GB RAMのものを使用した。OSはGNU/Linux Ubuntu 14.04である。スレッドはpthreadライブラリで実装した。なお、本実験は様々な問題ドメインとアルゴリズムを比較するために、\ref{sec:analysis1}章とは異なる実装のコードを利用した。

\subsection{HDA*のチューニング}
\label{sec:hdastar_tuning}

前章にて、Naive Hashは分配に問題があると分かった。また、BurnsらはA*探索の15 Puzzleドメインにおける実装の最適化について議論を行い、vectorによるオープンリストがheap実装より3倍程度速いことを示した\cite{burns2012implementing}。Korfの100 puzzleをインスタンスにこれらの比較を行った\ref{korf1985depth}。並列アルゴリズムは全て8スレッドの実行による。実行時間の上限は2000秒とした。

\begin{figure}
	\centering
	\begin{subfigure}{0.6\columnwidth}
		\includegraphics[width=\columnwidth]{eps/hdastar_tuning_walltime.pdf}
		\caption{tuning HDA* (walltime)}
		\label{fig:hdastar_tuning_walltime}
	\end{subfigure}
	\begin{subfigure}{0.6\columnwidth}
		\includegraphics[width=\columnwidth]{eps/hdastar_tuning_expd.pdf}
		\caption{tuning HDA* (search overhead)}
		\label{fig:hdastar_tuning_expd}
	\end{subfigure}
	\caption{zobrist vs haive hash, vector vs heap open list}
	\label{fig:hdastar_tuning}
\end{figure}

\ref{fig:hdastar_tuning_walltime}は横軸に実行時間、縦軸にその時間内に解けた問題の数を取っている。どの問題サイズにおいても、Zobrist Hashとvectorによる実装が一番速いと結論出来る。特にZobrist Hashを用いた実装はNaive Hashによる実装よりも2倍程度速い。\ref{fig:hdastar_tuning_expd}は横軸を展開ノード数にしたものである。図によると、Zobrist HashはNaive Hashよりも展開ノード数が小さい。Naive Hashはどの問題サイズでもおおよそZobrist Hashの２倍の展開ノード数になっている。よってZobrist Hashの実装の方が高速であるのは展開ノード数の違いによるものであると結論出来る。Zobrist HashがNaive Hashよりも大きく性能が優れるという結果は\ref{sec:analysis1}における分析結果とも一致する。


\subsection{SafePBNFのチューニング}
\label{sec:pbnf_tuning}

HDA*においてvector実装がheap実装よりも速いことが分かった。SafePBNFにおいてもKorfの100 puzzleを対象に比較を行った。\ref{fig:pbnf_tuning}が実行結果である。PBNFにおいては、HDA*ほどの高速化が得られないようである。heapに対するアクセスは$O(logn)$であるのに対してvectorは$O(1)$である。SafePBNFは沢山のオープンリストに分割されていて、各オープンリストが小さく、$O(logn)$と$O(1)$の差が小さい為、vector実装による高速化が小さいと考えられる。
SafePBNFのパラメータとして、NBlockの個数と最小探索ノード数がある。BurnsらはSliding-tile puzzle問題においてNBlock = 3360, 最小探索ノード数 = 8とした場合に最適であると示した。Burnsらの実験はdual quad-core Intel Xeon E5320 1.86GHzプロセッサ、16 GB RAMである。本実験の実験環境と類似している為、Burnsらの提案したパラメータを用いた。並列アルゴリズムは全て8スレッドの実行による。実行時間の上限は2000秒とした。


\begin{figure}
	\centering
	\begin{subfigure}{0.4\columnwidth}
		\includegraphics[width=\columnwidth]{eps/safepbnf_tuning_walltime.pdf}
		\caption{tuning SafePBNF (walltime)}
		\label{fig:safepbnf_tuning_walltime}
	\end{subfigure}
	\begin{subfigure}{0.4\columnwidth}
		\includegraphics[width=\columnwidth]{eps/safepbnf_tuning_expd.pdf}
		\caption{tuning SafePBNF (search overhead)}
		\label{fig:safepbnf_tuning_expd}
	\end{subfigure}
	\label{fig:safepbnf_tuning}
	\caption{vector vs heap}
\end{figure}

\subsection{HDA*とPBNFの性能比較実験}

\ref{sec:hdastar_tuning}より、HDA*はZobrist Hashingとvectorによる実装が最も速いと結論された。\ref{sec:pbnf_tuning}では、SafePBNFはvectorとheapによる実装で大きなパフォーマンスの違いは見られなかった。よって、vectorとheapの両方の実装で性能評価が必要である。並列アルゴリズムは全て8スレッドの実行による。どのドメイン・インスタンスも実行時間の上限は2000秒とした。

\begin{figure}
%	\centering
	\begin{subfigure}{0.4\columnwidth}
		\includegraphics[width=\columnwidth]{eps/15puzzle_vector_walltime.pdf}
		\caption{15 Puzzle (vector)}
		\label{fig:15puzzle_vector}
	\end{subfigure}
	\begin{subfigure}{0.4\columnwidth}
		\includegraphics[width=\columnwidth]{eps/15puzzle_heap_walltime.pdf}
		\caption{15 Puzzle (heap)}
		\label{fig:15puzzle_heap}
	\end{subfigure}
	\begin{subfigure}{0.4\columnwidth}
		\includegraphics[width=\columnwidth]{eps/24_walltime.pdf}
		\caption{24 Puzzle (vector)}
		\label{fig:24puzzle_vector}
	\end{subfigure}
	\begin{subfigure}{0.4\columnwidth}
		\includegraphics[width=\columnwidth]{eps/grid_walltime.pdf}
		\caption{Grid Pathfinding (vector)}
		\label{fig:grid}
	\end{subfigure}
	\begin{subfigure}{0.4\columnwidth}
		\includegraphics[width=\columnwidth]{eps/tsp_20_walltime.pdf}
		\caption{TSP (heap)}
		\label{fig:tsp_20_mst}
	\end{subfigure}
	\caption{HDA*とPBNFの実行速度の比較}
	\label{fig:comparison}
\end{figure}%

\begin{figure}
%	\centering
	\begin{subfigure}{0.4\columnwidth}
		\includegraphics[width=\columnwidth]{eps/15puzzle_vector_expd.pdf}
		\caption{15 Puzzle (vector)}
		\label{fig:15puzzle_vector_expd}
	\end{subfigure}

	\begin{subfigure}{0.4\columnwidth}
		\includegraphics[width=\columnwidth]{eps/15puzzle_heap_expd.pdf}
		\caption{15 Puzzle (heap)}
		\label{fig:15puzzle_heap_expd}
	\end{subfigure}

	\begin{subfigure}{0.4\columnwidth}
		\includegraphics[width=\columnwidth]{eps/24_expd.pdf}
		\caption{24 Puzzle (vector)}
		\label{fig:24puzzle_vector_expd}
	\end{subfigure}

	\begin{subfigure}{0.4\columnwidth}
		\includegraphics[width=\columnwidth]{eps/grid_expd.pdf}
		\caption{Grid Pathfinding (vector)}
		\label{fig:grid_expd}
	\end{subfigure}
	\centering
	\begin{subfigure}{0.4\columnwidth}
		\includegraphics[width=\columnwidth]{eps/tsp_20_expd.pdf}
		\caption{TSP (heap)}
		\label{fig:tsp_20_mst_expd}
	\end{subfigure}
	\caption{HDA*とPBNFの探索ノード数の比較}
	\label{fig:comparison_expd}
\end{figure}%


\ref{fig:comparison}が実行速度の比較である。特に実行時間の大きい問題ドメイン・インスタンスにおいて、HDA*はSafePBNFよりも実行速度で勝っている。

どのドメインでもHDA* vs. SafePBNFの探索ノード数はあまり変わらない。\ref{sec:analysis1}章の結論とこの結果を踏まえると、BurnsらがHDA*の探索オーバーヘッドを指摘したのはNaive Hashによる実装であったからであると結論出来るだろう。

Parallel A*はどのドメインにおいてもA*よりも遅くなってしまう。Parallel A*は非常にシンプルな並列アルゴリズムであるが、探索の高速化はもたらさない。

\ref{fig:15puzzle_heap}は15 Puzzleに対してheapで実装した場合の実行時間である。SafePBNFの利点として、Burnsらはオープンリストが小さい為、heapへのアクセスが速いということと挙げた\cite{Burns2010}。しかし、この実験結果はheap実装においてもHDA*SafePBNFよりもパフォーマンスに優れるということを示す。

どのドメインにも共通する傾向として、実行時間が5秒未満程度の小さい問題に対してはHDA*よりもSafePBNFの方が優れる場合が多い。特にGrid Pathfindingにおいて顕著に見られる。また、この時HDA*の展開ノード数はSafePBNFよりも大きい。\ref{sec:analysis1}章で述べたように、HDA*は実行時間の冒頭と末尾に探索オーバーヘッドがある。実行時間が短い場合、これらのオーバーヘッドの割合が大きくなる。よって、小さな問題インスタンスに対しては探索オーバーヘッドが大きく、SafePBNFの方が速いと考えられる。


\section{おわりに}

本研究の貢献は大きく分けて２つある。

\begin{enumerate}
\item HDA*の探索オーバーヘッドの定性的な分析

HDA*の探索オーバーヘッドの原因を３つに分類を行い、十分問題サイズが大きい場合に探索オーバーヘッドが無視出来る程度に小さいことを理論的に示した。また、高速化効率と探索オーバーヘッドを問題インスタンス毎に示すことで、それを実験的にも証明した。本実験は共有メモリ環境において行われたが、分散メモリ環境においても同様の結果が得られると推測している。その実験的な実証は今後の研究課題である。また、本研究は新しい探索オーバーヘッドの分析手法を示した。これは他の並列探索においても有効な分析方法であると考えられる。
\newline

\item HDA*とPBNFの再評価

先行研究の分析の問題点を指摘し、より正確かつミクロな分析を行った。実験により、マルチコア環境においても相応しい実装を行えばHDA*の方がパフォーマンスに優れるという結果を得た。また、本研究ではOptimal Searchを対象としたがSuboptimal Searchにおける実験は行っていない。Suboptimal Searchにおける性能比較は今後研究課題である。簡易ヒューリスティックを用いたTravelling Salesperson ProblemにおいてはPBNFの方がHDA*よりも速いという結果を得た。これはPBNFのheapの方が小さい為、heapへのアクセスが速い為ではないかと考えられる。heapは複数に分割することが出来る。分割heapを用いることで実数コストドメインにおけるHDA*, PBNFのパフォーマンスを向上させることが出来るかもしれない。これは今後の研究課題である。

\end{enumerate}

\section{謝辞}

研究室の先輩方にはミーティングや中間発表などで沢山の有益なアドバイスを頂きました。特に同期の堀江君とは本当に毎日議論を重ね、沢山のことを学ばせて頂きました。指導教員である福永先生には、初めて情報科学に触る私に対してとても丁寧にご指導して頂きました。研究とは、情報科学とは、プログラミングとは、あらゆることを教えて頂きました。何よりも、研究が楽しいということを教えて頂いたことに深く感謝致します。修士課程でも、一つでも多くのことを学ばせて頂きたいと思います。

\bibliographystyle{jplain}
\bibliography{b}

\end{document}
